{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"BmogSVGfYcOs"},"id":"BmogSVGfYcOs","execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd '/content/drive/MyDrive/dataset brain tumor/dataset'"],"metadata":{"id":"alDT-SKLYfia"},"id":"alDT-SKLYfia","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip 'axial_t1wce_2_class' -d '/dataset unzipped'"],"metadata":{"id":"Pz8docfHYhUK"},"id":"Pz8docfHYhUK","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip 'coronal_t1wce_2_class' -d '/dataset unzipped'"],"metadata":{"id":"ksLOwHfxYjbf"},"id":"ksLOwHfxYjbf","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip 'sagittal_t1wce_2_class' -d '/dataset unzipped'"],"metadata":{"id":"nm2aA8tYYlHi"},"id":"nm2aA8tYYlHi","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"0ca9e015","metadata":{"id":"0ca9e015"},"outputs":[],"source":["# Data Manipulation\n","import numpy as np\n","import pandas as pd\n","import os\n","# Visualization/Image Processing\n","import cv2\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","# Machine Learning\n","import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, Input, BatchNormalization, Flatten, MaxPool2D, MaxPooling2D, Dense, Activation, Dropout\n","from PIL import Image\n","# Other\n","from pathlib import Path\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","from tensorflow import keras\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.models import Model\n","import xml.etree.ElementTree as ET\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import layers\n","import imutils\n","from PIL import Image, ImageEnhance"]},{"cell_type":"code","source":["%cd '/dataset unzipped'"],"metadata":{"id":"eznf1ZurYo0M"},"id":"eznf1ZurYo0M","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def crop_brain_contour(image, plot=False):\n","    \n","    #import imutils\n","    #import cv2\n","    #from matplotlib import pyplot as plt\n","    \n","    brightness = 30\n","    image = np.int16(image)\n","    image = image + brightness\n","    image = np.clip(image,0,255)\n","    image = np.uint8(image)\n","    #image_enhance = ImageEnhance.Brightness(image)\n","    #factor = 1.5\n","    #image = image_enhance.enhance(factor)\n","\n","    # Convert the image to grayscale, and blur it slightl\n","    \n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n","\n","    # Threshold the image, then perform a series of erosions +\n","    # dilations to remove any small regions of noise\n","    #thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n","    thresh = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)[1]\n","    #thresh = cv2.erode(thresh, None, iterations=2)\n","    #thresh = cv2.dilate(thresh, None, iterations=2)\n","\n","    # Find contours in thresholded image, then grab the largest one\n","    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    cnts = imutils.grab_contours(cnts)\n","    c = max(cnts, key=cv2.contourArea)\n","    \n","\n","    # Find the extreme points\n","    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n","    extRight = tuple(c[c[:, :, 0].argmax()][0])\n","    extTop = tuple(c[c[:, :, 1].argmin()][0])\n","    extBot = tuple(c[c[:, :, 1].argmax()][0])\n","    \n","    # crop new image out of the original image using the four extreme points (left, right, top, bottom)\n","    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]            \n","\n","    if plot:\n","        plt.figure()\n","\n","        plt.subplot(1, 2, 1)\n","        plt.imshow(image)\n","        \n","        plt.tick_params(axis='both', which='both', \n","                        top=False, bottom=False, left=False, right=False,\n","                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n","        \n","        plt.title('Original Image')\n","            \n","        plt.subplot(1, 2, 2)\n","        plt.imshow(new_image)\n","\n","        plt.tick_params(axis='both', which='both', \n","                        top=False, bottom=False, left=False, right=False,\n","                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n","\n","        plt.title('Cropped Image')\n","        \n","        plt.show()\n","\n","    #add contrast\n","    #kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n","    # Top Hat Transform\n","    #topHat = cv2.morphologyEx(new_image, cv2.MORPH_TOPHAT, kernel)\n","    # Black Hat Transform\n","    #blackHat = cv2.morphologyEx(new_image, cv2.MORPH_BLACKHAT, kernel)\n","    \n","    #new_image = new_image + topHat - blackHat\n","    \n","    return new_image,extLeft,extRight,extTop,extBot"],"metadata":{"id":"BOXyuNdeYvt7"},"id":"BOXyuNdeYvt7","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"c43f6daa","metadata":{"id":"c43f6daa"},"outputs":[],"source":["#Codice per rendere l'immagine quadrata \n","def make_square(im, fill_color=(0, 0, 0, 0)):\n","    x, y = im.shape[0], im.shape[1]\n","    size = max(x, y)\n","    BLACK = [0, 0, 0]\n","    new_im = cv2.copyMakeBorder(im,int((size-y)/2),int((size-y)/2),int((size-x)/2),int((size-x)/2),cv2.BORDER_CONSTANT, value = BLACK)\n","    return new_im"]},{"cell_type":"code","execution_count":null,"id":"4759b91e","metadata":{"id":"4759b91e"},"outputs":[],"source":["#Bounding box with one tumor\n","lab = ['axial_t1wce_2_class','coronal_t1wce_2_class', 'sagittal_t1wce_2_class']\n","X_train = []\n","bb = []\n","temp_array  = []\n","count = 0;\n","temp_array  = []\n","extLeft_coords_x = []\n","extLeft_coords_y = []\n","extRight_coords_x = []\n","extRight_coords_y = []\n","extTop_coords_x = []\n","extTop_coords_y = []\n","extBot_coords_x = []\n","extBot_coords_y = []\n","image_width = []\n","image_height = []\n","\n","\n","extLeft_coords_x_test = []\n","extLeft_coords_y_test = []\n","extRight_coords_x_test = []\n","extRight_coords_y_test = []\n","extTop_coords_x_test = []\n","extTop_coords_y_test = []\n","extBot_coords_x_test = []\n","extBot_coords_y_test = []\n","images_width_test = []\n","images_height_test = []\n","width_new_im = []\n","height_new_im = []\n","traslazione_x_test = []\n","traslazione_y_test = []\n","\n","image_size = 180\n","\n","for i in lab:\n","    folderPath = os.path.join('./',i,'images','train')\n","    for j in sorted(os.listdir(folderPath)):\n","        #load the image\n","        img = cv2.imread(os.path.join(folderPath,j))\n","        image_width.append(img.shape[1])\n","        image_height.append(img.shape[0])\n","        # crop the brain and ignore the unnecessary rest part of the image\n","        image,extLeft,extRight,extTop,extBot = crop_brain_contour(img,False)\n","\n","        extLeft_coords_x.append(extLeft[0])\n","        extLeft_coords_y.append(extLeft[1])\n","        extRight_coords_x.append(extRight[0])\n","        extRight_coords_y.append(extRight[1])\n","        extTop_coords_x.append(extTop[0])\n","        extTop_coords_y.append(extTop[1])\n","        extBot_coords_x.append(extBot[0])\n","        extBot_coords_y.append(extBot[1])\n","        # resize image\n","        image = cv2.resize(image, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n","        \n","        #if img.shape[0] != img.shape[1]:\n","        #    img = make_square(img, fill_color=(0, 0, 0, 0))\n","        #img = cv2.resize(img,(image_size, image_size))\n","\n","        X_train.append(image)\n","image_index = 0\n","bb_train = np.zeros((len(X_train),4))\n","for i in lab:\n","    labelsPath = os.path.join('./',i,'labels','train')\n","    for j in sorted(os.listdir(labelsPath)):\n","        with open(os.path.join(labelsPath,j), encoding=\"utf-8\") as f:\n","            for line in f:\n","                num = list(map(float,line.split(\" \")))\n","                temp_array = []\n","                for k in num:\n","                  temp_array.append(k)\n","                temp_array.pop(0)\n","\n","                temp_array[0] = temp_array[0]*image_width[count] #centro x immagine originale\n","                temp_array[0] = temp_array[0]-extLeft_coords_x[count]\n","                temp_array[0] = (temp_array[0]/(extRight_coords_x[count]-extLeft_coords_x[count]))*image_size\n","                \n","                temp_array[1] = temp_array[1]*image_height[count]\n","                temp_array[1] = temp_array[1]-extTop_coords_y[count]\n","                temp_array[1] = (temp_array[1]/(extBot_coords_y[count]-extTop_coords_y[count]))*image_size\n","                \n","                temp_array[2] = temp_array[2]*(image_width[count])\n","                temp_array[2] = (temp_array[2]/(extRight_coords_x[count]-extLeft_coords_x[count]))*image_size\n","                \n","                temp_array[3] = temp_array[3]*(image_height[count])\n","                temp_array[3] = (temp_array[3]/(extBot_coords_y[count]-extTop_coords_y[count]))*image_size\n","\n","                #print(temp_array)\n","                bb_train[image_index] = np.array([temp_array])\n","                #print(bb_train[image_index])\n","            image_index += 1\n","            count += 1\n","\n","X_test = []\n","for i in lab:\n","    folderPath = os.path.join('./',i,'images','test')\n","    for j in sorted(os.listdir(folderPath)):\n","        #load the image\n","        img = cv2.imread(os.path.join(folderPath,j))\n","        images_width_test.append(img.shape[1])\n","        images_height_test.append(img.shape[0])\n","\n","        # crop the brain and ignore the unnecessary rest part of the image\n","        image_test,extLeft_test,extRight_test,extTop_test,extBot_test = crop_brain_contour(img,False)\n","        extLeft_coords_x_test.append(extLeft_test[0])\n","        extLeft_coords_y_test.append(extLeft_test[1])\n","        extRight_coords_x_test.append(extRight_test[0])\n","        extRight_coords_y_test.append(extRight_test[1])\n","        extTop_coords_x_test.append(extTop_test[0])\n","        extTop_coords_y_test.append(extTop_test[1])\n","        extBot_coords_x_test.append(extBot_test[0])\n","        extBot_coords_y_test.append(extBot_test[1])\n","        # resize image\n","        image_test = cv2.resize(image_test, dsize=(image_size, image_size), interpolation=cv2.INTER_CUBIC)\n","        #if img.shape[0] != img.shape[1]:\n","            #img = make_square(img, fill_color=(0, 0, 0, 0))\n","        #image_test = cv2.resize(img,(image_size, image_size))\n","        X_test.append(image_test)\n","\n","image_index = 0\n","count_test = 0;\n","bb_test = np.zeros((len(X_test),4))\n","for i in lab:\n","    labelsPath = os.path.join('./',i,'labels','test')\n","    for j in sorted(os.listdir(labelsPath)):\n","        with open(os.path.join(labelsPath,j), encoding=\"utf-8\") as f:\n","            for line in f:\n","                num = list(map(float,line.split(\" \")))\n","                temp_array = []\n","                for k in num:\n","                    temp_array.append(k)\n","                temp_array.pop(0)\n","\n","                width_new_im.append(extRight_coords_x_test[count_test]-extLeft_coords_x_test[count_test])\n","                height_new_im.append(extBot_coords_y_test[count_test]-extTop_coords_y_test[count_test])\n","                \n","                temp_array[0] = temp_array[0]*images_width_test[count_test] #centro x immagine originale\n","                temp_array[0] = temp_array[0]-extLeft_coords_x_test[count_test]\n","                temp_array[0] = (temp_array[0]/(extRight_coords_x_test[count_test]-extLeft_coords_x_test[count_test]))*image_size\n","                \n","                temp_array[1] = temp_array[1]*images_height_test[count_test]\n","                temp_array[1] = temp_array[1]-extTop_coords_y_test[count_test]\n","                temp_array[1] = (temp_array[1]/(extBot_coords_y_test[count_test]-extTop_coords_y_test[count_test]))*image_size\n","                \n","                temp_array[2] = temp_array[2]*(images_width_test[count_test])\n","                temp_array[2] = (temp_array[2]/(extRight_coords_x_test[count_test]-extLeft_coords_x_test[count_test]))*image_size\n","                \n","                \n","                temp_array[3] = temp_array[3]*(images_height_test[count_test])\n","                temp_array[3] = (temp_array[3]/(extBot_coords_y_test[count_test]-extTop_coords_y_test[count_test]))*image_size                 \n","            \n","                bb_test[image_index] = np.array([temp_array])\n","                #print(bb_test[image_index])\n","            image_index += 1\n","            count_test += 1\n","\n","#print(bb_test[30])\n","#print(extRight_coords_x_test[30])\n","#print(extLeft_coords_x_test[30])\n","#ex_img = cv2.imread('./axial_t1wce_2_class/images/train/00095_200.jpg')\n","#ex_new_img,extLeft,extRight,extTop,extBot = crop_brain_contour(ex_img, True)"]},{"cell_type":"code","execution_count":null,"id":"7af6645e","metadata":{"id":"7af6645e"},"outputs":[],"source":["#prepare dataset \n","train_dataset = ImageDataGenerator()\n","val_dataset = ImageDataGenerator()\n","test_dataset = ImageDataGenerator()"]},{"cell_type":"code","execution_count":null,"id":"a24d7c0a","metadata":{"id":"a24d7c0a"},"outputs":[],"source":["datagen = ImageDataGenerator(\n","  rescale = 1./255,\n","  #rotation_range = 5,\n","  shear_range = 0.02,\n","  #zoom_range = 0.02, \n","  samplewise_center = True,\n","  samplewise_std_normalization = True\n","  #horizontal_flip=True\n",")\n","\n","val_data_gen = ImageDataGenerator(rescale = 1./255)"]},{"cell_type":"code","execution_count":null,"id":"7d593dd9","metadata":{"id":"7d593dd9"},"outputs":[],"source":["#array conversion\n","X_train = np.array(X_train)\n","X_test = np.array(X_test)"]},{"cell_type":"code","execution_count":null,"id":"ae8f4400","metadata":{"id":"ae8f4400"},"outputs":[],"source":["#Shuffle\n","X_train, bb_train = shuffle(X_train, bb_train)"]},{"cell_type":"code","execution_count":null,"id":"04e1025e","metadata":{"id":"04e1025e"},"outputs":[],"source":["#Validation set created\n","X_train, X_val, bb_train, bb_val = train_test_split(X_train, bb_train, test_size = 0.1, shuffle = False)"]},{"cell_type":"code","execution_count":null,"id":"3d9b4a10","metadata":{"id":"3d9b4a10"},"outputs":[],"source":["tf.keras.backend.set_image_data_format('channels_last')\n","BATCH_SIZE = 16\n","#save_path = os.path.join('./', 'model_from_scratch')\n","train_dataset = train_dataset.flow(X_train, bb_train, batch_size = BATCH_SIZE)\n","val_dataset = val_dataset.flow(X_val, bb_val, batch_size = BATCH_SIZE)\n","test_dataset = test_dataset.flow(X_test, bb_test)"]},{"cell_type":"code","execution_count":null,"id":"6bf1bc8a","metadata":{"id":"6bf1bc8a"},"outputs":[],"source":["input_ = Input(shape=[180,180, 3])\n","\n","x = input_\n","\n","for i in range(10):\n","    n_filters = 2**(i + 3)\n","    x = Conv2D(n_filters, 3, activation='relu', padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = MaxPool2D(2, padding='same')(x)\n","\n","x = Flatten()(x)\n","x = Dense(256, activation='relu')(x)\n","x = Dense(32, activation='relu')(x)\n","output = Dense(4, name='coords')(x)\n","\n","model = tf.keras.models.Model(input_, output)\n","model.summary()"]},{"cell_type":"code","execution_count":null,"id":"91426a87","metadata":{"id":"91426a87"},"outputs":[],"source":["# Draw the predicted bounding boxes\n","def display_image(img, bbox_coords, pred_coords):\n","    if len(bbox_coords) == 4: #in rosso\n","        xmin, ymin, height, width = bbox_coords\n","        img = cv2.rectangle(img, (int(xmin-height/2), int(ymin-width/2)), (int(xmin+height/2), int(ymin+width/2)), (255, 0, 0), 1)\n","    print(len(pred_coords))    \n","    if len(pred_coords) == 4: #in verde\n","        xmin1, ymin1, height1, width1 = pred_coords\n","        img = cv2.rectangle(img, (int(xmin1-height1/2), int(ymin1-width1/2)), (int(xmin1+height1/2), int(ymin1+width1/2)), (0, 255, 0), 1)\n","    plt.imshow(img)\n","    plt.xticks([])\n","    plt.yticks([])"]},{"cell_type":"code","execution_count":null,"id":"adb14654","metadata":{"id":"adb14654"},"outputs":[],"source":["#To test the model\n","def test_model(model):\n","    rand_index = np.random.randint(0, bb_test.shape[0])\n","    pred_bbox = model.predict(X_test)[rand_index]\n","    img_original = X_test[rand_index]\n","    img = img_original.copy()\n","    coords = bb_test[rand_index]\n","    #example, label = next(datagen)\n","    #X = example['image']\n","    #y = label['coords']\n","    #pred_bbox = model.predict(X)[0]\n","    #img = X[0]\n","    #gt_coords = y[0]\n","    \n","    display_image(img,bbox_coords = coords, pred_coords=pred_bbox)\n","\n","def test(model):\n","    \n","    plt.figure(figsize=(15,7))\n","    for i in range(3):\n","        plt.subplot(1, 3, i + 1)\n","        test_model(model)    \n","    plt.show()\n","\n","class ShowTestImages(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        test(self.model)\n","        "]},{"cell_type":"code","execution_count":null,"id":"2bb25a3c","metadata":{"id":"2bb25a3c"},"outputs":[],"source":["callbacks_list = [\n","    ShowTestImages()\n","]"]},{"cell_type":"code","source":["METRIC_THRESH = 0.3\n","\n","def raw_iou(y_true, y_pred):\n","    results = []\n","    for i in range(0,y_true.shape[0]):\n","\n","\n","        boxTrue_width = y_true[i,2]\n","        boxTrue_height = y_true[i,3]\n","        x_boxTrue_tleft = y_true[i,0]-boxTrue_width/2  # numpy index selection\n","        y_boxTrue_tleft = y_true[i,1]-boxTrue_height/2\n","    \n","        area_boxTrue = (boxTrue_width * boxTrue_height)\n","\n","        # boxPred\n","        boxPred_width = y_pred[i,2]\n","        boxPred_height = y_pred[i,3]\n","        x_boxPred_tleft = y_pred[i,0]-boxPred_width/2  \n","        y_boxPred_tleft = y_pred[i,1]-boxPred_height/2\n","    \n","        area_boxPred = (boxPred_width * boxPred_height)\n","\n","\n","        # calculate the bottom right coordinates for boxTrue and boxPred\n","\n","        # boxTrue\n","        x_boxTrue_br = x_boxTrue_tleft + boxTrue_width\n","        y_boxTrue_br = y_boxTrue_tleft + boxTrue_height # Version 2 revision\n","\n","        # boxPred\n","        x_boxPred_br = x_boxPred_tleft + boxPred_width\n","        y_boxPred_br = y_boxPred_tleft + boxPred_height # Version 2 revision\n","\n","\n","        # calculate the top left and bottom right coordinates for the intersection box, boxInt\n","\n","        # boxInt - top left coords\n","        x_boxInt_tleft = np.max([x_boxTrue_tleft,x_boxPred_tleft])\n","        y_boxInt_tleft = np.max([y_boxTrue_tleft,y_boxPred_tleft]) # Version 2 revision\n","\n","        # boxInt - bottom right coords\n","        x_boxInt_br = np.min([x_boxTrue_br,x_boxPred_br])\n","        y_boxInt_br = np.min([y_boxTrue_br,y_boxPred_br]) \n","\n","        # Calculate the area of boxInt, i.e. the area of the intersection \n","        # between boxTrue and boxPred.\n","        # The np.max() function forces the intersection area to 0 if the boxes don't overlap.\n","        \n","        \n","        # Version 2 revision\n","        area_of_intersection = \\\n","        np.max([0,(x_boxInt_br - x_boxInt_tleft)]) * np.max([0,(y_boxInt_br - y_boxInt_tleft)])\n","\n","        iou = np.mean(area_of_intersection / ((area_boxTrue + area_boxPred) - area_of_intersection)).astype(np.float32)\n","\n","\n","        # This must match the type used in py_func\n","        results.append(iou)\n","    return np.mean(results)\n","\n","def IoU(y_true, y_pred):\n","    iou = tf.numpy_function(raw_iou, [y_true, y_pred], tf.float32)\n","    return iou"],"metadata":{"id":"9m5306eiaiK-"},"id":"9m5306eiaiK-","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"06cd51f4","metadata":{"id":"06cd51f4"},"outputs":[],"source":["model.compile(\n","    loss={\n","        'coords': 'mae'\n","    },\n","    optimizer=tf.keras.optimizers.Adam(1e-3),\n","    metrics=[IoU]\n",")"]},{"cell_type":"code","execution_count":null,"id":"4c3f9e48","metadata":{"id":"4c3f9e48"},"outputs":[],"source":["model.fit(\n","        train_dataset,\n","        epochs=100,\n","        validation_data = val_dataset,\n","        callbacks = callbacks_list\n","        )"]},{"cell_type":"code","execution_count":null,"id":"b44de4d4","metadata":{"id":"b44de4d4"},"outputs":[],"source":["pd.DataFrame(model.history.history).plot()"]},{"cell_type":"code","execution_count":null,"id":"d4142b7c","metadata":{"id":"d4142b7c"},"outputs":[],"source":["model.evaluate(test_dataset)"]},{"cell_type":"code","execution_count":null,"id":"f15bde1b","metadata":{"id":"f15bde1b"},"outputs":[],"source":["#Save model\n","model.save('./model_fromScratch')"]},{"cell_type":"code","execution_count":null,"id":"43ad036e","metadata":{"id":"43ad036e"},"outputs":[],"source":["#Load model\n","model = tf.keras.models.load_model('./model_fromScratch')"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"colab":{"provenance":[{"file_id":"https://github.com/frnocentini/brain-tumor-object-dectection/blob/main/Brain%20Tumor%20Object%20Detection-Scratch_Crop.ipynb","timestamp":1683366377921},{"file_id":"https://github.com/frnocentini/brain-tumor-object-dectection/blob/main/Brain%20Tumor%20Object%20Detection-Scratch.ipynb","timestamp":1683365930916}],"gpuType":"T4"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}